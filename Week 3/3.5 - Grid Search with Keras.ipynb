{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13047,"status":"ok","timestamp":1643744905630,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"},"user_tz":300},"id":"kEUXk5xlvg9e","outputId":"69cd0d4c-fa86-48db-f7c2-376432a4e4c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scikeras\n","  Downloading scikeras-0.6.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\linhto\\miniconda3\\envs\\ba820\\lib\\site-packages (from scikeras) (1.0.1)\n","Requirement already satisfied: packaging<22.0,>=0.21 in c:\\users\\linhto\\miniconda3\\envs\\ba820\\lib\\site-packages (from scikeras) (21.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\linhto\\miniconda3\\envs\\ba820\\lib\\site-packages (from packaging<22.0,>=0.21->scikeras) (2.4.7)\n","Requirement already satisfied: numpy>=1.14.6 in c:\\users\\linhto\\miniconda3\\envs\\ba820\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.20.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\linhto\\miniconda3\\envs\\ba820\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in c:\\users\\linhto\\miniconda3\\envs\\ba820\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in c:\\users\\linhto\\miniconda3\\envs\\ba820\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.7.1)\n","Installing collected packages: scikeras\n","Successfully installed scikeras-0.6.0\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n","57344/57026 [==============================] - 0s 0us/step\n","65536/57026 [==================================] - 0s 0us/step\n"]}],"source":["try:\n","    from scikeras.wrappers import KerasRegressor                     \n","except ImportError:\n","    !pip install scikeras\n","    from scikeras.wrappers import KerasRegressor\n","    \n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import sklearn\n","from sklearn.pipeline import Pipeline # for setting up a pre-processing / tuning pipeline.\n","from sklearn.preprocessing import RobustScaler # Here, we are going to normalize inputs (the ML Pipeline framework from sklearn can implement this.)\n","\n","# So, we are going back to the Boston Housing data here.\n","from tensorflow.keras.datasets import boston_housing\n","(train_data, train_targets), (test_data, test_targets) = (boston_housing.load_data())"]},{"cell_type":"markdown","metadata":{"id":"Xvf2i7v1zv61"},"source":["#*Grid Search CV With Keras Model*"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1643745184363,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"},"user_tz":300},"id":"dpJeCA_BvdCj","outputId":"a49d9cf4-6036-4724-a054-5d8681c0b501"},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'activation', 'units', 'numLayers'])\n"]}],"source":["# Make sure you set your custom parameters for training as arguments in your model creation function.\n","def create_model(loss=\"mean_squared_error\",optimizer=\"sgd\",activation=\"relu\",units=100,numLayers=2, batch_size=10):\n","    \n","    # I beleve that you need to explicitly declare an input layer for the scikeras wrapper to work... \n","    model = keras.Sequential([\n","        layers.Input(train_data.shape[1]), \n","        layers.Dense(units, activation=\"relu\")             \n","    ])\n","\n","    if numLayers == 2:\n","        model.add(layers.Dense(units, activation=\"relu\"))\n","\n","    model.add(layers.Dense(1, activation=activation))\n","\n","    model.compile(loss=loss,optimizer=optimizer, metrics=['mse'])\n","    return model\n","\n","# You also need to specify the 'custom' parameters here that you want to add, for them to show up as a trainable parameter in GridSearchCV.\n","regf = KerasRegressor(model=create_model, loss=\"mean_squared_error\", optimizer=\"adam\", activation=\"relu\", units=100, numLayers=2, batch_size=10, verbose=0)\n","\n","# Note you can also do a grid search over an sklearn pipeline, so you can search over diferent types of data pre-processing approaches too!\n","#ml_pipeline = Pipeline([(\"Normalize_with_centering\", RobustScaler()), (\"Model\", regf)])\n","\n","# Here are the configurable parameters we can now search over for either object. \n","print(regf.get_params().keys())\n","#print(ml_pipeline.get_params().keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qZZz2PQF2UgH"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"twEp-TV23rUM"},"source":["And this is how I would invoke my grid search... "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16382,"status":"ok","timestamp":1643745305616,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"},"user_tz":300},"id":"CLhnTa921I0-","outputId":"21447d98-7ca7-4362-903f-cb5bd7e91a6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 4 candidates, totalling 20 fits\n","[CV 1/5; 1/4] START numLayers=1, units=100......................................\n","[CV 1/5; 1/4] END .....numLayers=1, units=100;, score=-20.121 total time=   1.0s\n","[CV 2/5; 1/4] START numLayers=1, units=100......................................\n","[CV 2/5; 1/4] END .....numLayers=1, units=100;, score=-23.710 total time=   0.3s\n","[CV 3/5; 1/4] START numLayers=1, units=100......................................\n","[CV 3/5; 1/4] END .....numLayers=1, units=100;, score=-21.856 total time=   0.3s\n","[CV 4/5; 1/4] START numLayers=1, units=100......................................\n","[CV 4/5; 1/4] END .....numLayers=1, units=100;, score=-22.623 total time=   0.3s\n","[CV 5/5; 1/4] START numLayers=1, units=100......................................\n","[CV 5/5; 1/4] END .....numLayers=1, units=100;, score=-23.681 total time=   0.4s\n","[CV 1/5; 2/4] START numLayers=1, units=125......................................\n","[CV 1/5; 2/4] END .....numLayers=1, units=125;, score=-20.121 total time=   0.3s\n","[CV 2/5; 2/4] START numLayers=1, units=125......................................\n","[CV 2/5; 2/4] END .....numLayers=1, units=125;, score=-23.710 total time=   0.3s\n","[CV 3/5; 2/4] START numLayers=1, units=125......................................\n","[CV 3/5; 2/4] END .....numLayers=1, units=125;, score=-21.856 total time=   0.3s\n","[CV 4/5; 2/4] START numLayers=1, units=125......................................\n","[CV 4/5; 2/4] END .....numLayers=1, units=125;, score=-22.623 total time=   0.3s\n","[CV 5/5; 2/4] START numLayers=1, units=125......................................\n","[CV 5/5; 2/4] END .....numLayers=1, units=125;, score=-23.681 total time=   0.3s\n","[CV 1/5; 3/4] START numLayers=2, units=100......................................\n","[CV 1/5; 3/4] END .....numLayers=2, units=100;, score=-20.121 total time=   0.3s\n","[CV 2/5; 3/4] START numLayers=2, units=100......................................\n","[CV 2/5; 3/4] END .....numLayers=2, units=100;, score=-23.710 total time=   0.3s\n","[CV 3/5; 3/4] START numLayers=2, units=100......................................\n","[CV 3/5; 3/4] END .....numLayers=2, units=100;, score=-21.856 total time=   0.3s\n","[CV 4/5; 3/4] START numLayers=2, units=100......................................\n","[CV 4/5; 3/4] END .....numLayers=2, units=100;, score=-22.623 total time=   0.3s\n","[CV 5/5; 3/4] START numLayers=2, units=100......................................\n","[CV 5/5; 3/4] END .....numLayers=2, units=100;, score=-23.681 total time=   0.3s\n","[CV 1/5; 4/4] START numLayers=2, units=125......................................\n","[CV 1/5; 4/4] END .....numLayers=2, units=125;, score=-20.121 total time=   0.3s\n","[CV 2/5; 4/4] START numLayers=2, units=125......................................\n","[CV 2/5; 4/4] END .....numLayers=2, units=125;, score=-23.710 total time=   0.3s\n","[CV 3/5; 4/4] START numLayers=2, units=125......................................\n","[CV 3/5; 4/4] END .....numLayers=2, units=125;, score=-21.856 total time=   0.3s\n","[CV 4/5; 4/4] START numLayers=2, units=125......................................\n","[CV 4/5; 4/4] END .....numLayers=2, units=125;, score=-22.623 total time=   0.3s\n","[CV 5/5; 4/4] START numLayers=2, units=125......................................\n","[CV 5/5; 4/4] END .....numLayers=2, units=125;, score=-23.681 total time=   0.3s\n"]},{"data":{"text/plain":["GridSearchCV(estimator=KerasRegressor(activation='relu', batch_size=10, loss='mean_squared_error', model=<function create_model at 0x00000271D70A5D30>, numLayers=2, optimizer='adam', units=100, verbose=0),\n","             param_grid={'numLayers': [1, 2], 'units': [100, 125]},\n","             scoring='neg_mean_absolute_error', verbose=11)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import GridSearchCV\n","import numpy as np\n","\n","# Because we are creating the models but are not compiling them yet (we will let the grid fit compile the models on the fly),\n","# this will produce a bunch of warnings. I'm just suppressing the warnings. \n","#import logging, os\n","#logging.disable(logging.WARNING)\n","#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n","\n","params = {\n","    \"numLayers\": [1,2],\n","    \"units\": [100,125]\n","    #\"activation\": ['relu','selu',None],\n","    #\"batch_size\": [25,50],\n","    #\"epochs\": [10,20,30]\n","}\n","\n","params_pipe = {\n","    \"Model__numLayers\": [1,2],\n","    \"Model__units\": [100,500],\n","    \"Model__activation\": ['relu','selu',None],\n","    \"Model__batch_size\": [25,50],\n","    \"Model__epochs\":[10,20,30]\n","}\n","\n","grid = GridSearchCV(regf, params, scoring='neg_mean_absolute_error',verbose=11)#,cv=10)\n","#grid = GridSearchCV(ml_pipeline, params_pipe, scoring='neg_mean_absolute_error',verbose=11)#,cv=10)\n","\n","grid.fit(train_data, train_targets)"]},{"cell_type":"markdown","metadata":{"id":"L-ZBoMDM3wKF"},"source":["I can then extract the parameters that yielded the top performance... "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1643745332882,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"},"user_tz":300},"id":"UISkU-jewLVB","outputId":"96bb8f66-1408-4764-ab2d-f07983ca831c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Score  : -22.398225308641976\n","Best Params : {'numLayers': 1, 'units': 100}\n"]}],"source":["print(f\"Best Score  : {grid.best_score_}\")\n","print(f\"Best Params : {grid.best_params_}\")"]},{"cell_type":"markdown","metadata":{"id":"F8X2ajBn32fa"},"source":["Finally, a little function that looks at pairs of parameter values, and the associated model performance, holding all other parameters to their ideal values. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eRilfjohwhxn"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","def plot_results(index='units', columns='activation'):\n","    index = 'param_' + index\n","    columns = 'param_' + columns\n","\n","    # prepare the results into a pandas.DataFrame\n","    df = pd.DataFrame(grid.cv_results_)\n","\n","    # Remove the other by selecting their best values (from gscv.best_params_)\n","    other = [c for c in df.columns if c[:6] == 'param_']\n","    other.remove(index)\n","    other.remove(columns)\n","\n","    # Set all other parameters to their \"top\" values.\n","    for col in other:\n","        df = df[df[col] == grid.best_params_[col[6:]]]\n","\n","    # Create pivot tables for easy plotting\n","    table_mean = df.pivot_table(index=index, columns=columns,\n","                                values=['mean_test_score'])\n","    \n","    # plot the pivot tables\n","    plt.figure()\n","    ax = plt.gca()\n","    for col_mean in table_mean.columns:\n","        table_mean[col_mean].plot(marker='o',label=col_mean)\n","    plt.title('Grid-search results (higher is better)')\n","    plt.ylabel('- Mean Absolute Error')\n","    plt.legend(title=table_mean.columns.names)\n","    plt.show()\n","\n","plot_results(index='units', columns='numLayers')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOnC3EU2njFbPjY2rGg0Xee","collapsed_sections":[],"name":"3.5 - Grid Search with Keras.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}
